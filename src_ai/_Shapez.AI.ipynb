{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECO3801 - Shapez.AI Project\n",
    "09:21:04 Friday September 20, 2024\n",
    "\n",
    "Student name:    &emsp;Cain Bruhn-Tanzer \\\n",
    "Student ID:      &emsp;&emsp;&ensp;s4535376 \\\n",
    "GitHub repo:     &emsp;&ensp; https://github.com/CainOCE/Shapez.ai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Static Goal List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "/**\n",
    " * need the list of goals\n",
    " * need a way to send the static required amount i dont know if we\n",
    " * can because the way we have it at the moment we have it we only\n",
    " * send through it once.\n",
    " */\n",
    "\n",
    "// CuCuCuCu\n",
    "// ----CuCu\n",
    "// RuRuRuRu\n",
    "// RuRU----\n",
    "// Cu----Cu\n",
    "// Cu------\n",
    "// CrCrCrCr\n",
    "// RbRb----\n",
    "// CpCpCpCp\n",
    "// ScScScSc\n",
    "// CgScScCg\n",
    "// CbCbCbRb:CwCwCwCw\n",
    "// RpRpRpRp:CwCwCwCw\n",
    "// --Cg----:--Cr----\n",
    "// SrSrSrSr:CyCyCyCy\n",
    "// SrSrSrSr:CyCyCyCy:SwSwSwSw\n",
    "// CbRbRbCb:CwCwCwCw:WbWbWbWb\n",
    "// Sg----Sg:CgCgCgCg:--CyCy--\n",
    "// CpRpCp--:SwSwSwSw\n",
    "// RuCw--Cw:----Ru--\n",
    "// CrCwCrCw:CwCrCwCr:CrCwCrCw:CwCrCwCr\n",
    "// Cg----Cr:Cw----Cw:Sy------:Cy----Cy\n",
    "// CcSyCcSy:SyCcSyCc:CcSyCcSy\n",
    "// CcRcCcRc:RwCwRwCw:Sr--Sw--:CyCyCyCy\n",
    "// Rg--Rg--:CwRwCwRw:--Rg--Rg\n",
    "// CbCuCbCu:Sr------:--CrSrCr:CwCwCwCw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rhys Game Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "\"\"\"\n",
    "set up game in simple version like gym\n",
    "- need a step function\n",
    "-\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "if we could make a simple python copy of the game could be useful... idk discuss w others\n",
    "\n",
    "during training will we require the chrome to be running, will make training super slow\n",
    "this is a where our version of the game could run much faster\n",
    "\n",
    "save model at end??\n",
    "\n",
    "simplify as much as possible:\n",
    "- extractors (1)\n",
    "- belts (2)\n",
    "- resource (-1, -2, -3, -4) -- or maybe some hash code like describing the products\n",
    "- HUB (3)\n",
    "- empty (0)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class shapezGym(gym.Env):\n",
    "\n",
    "    # buildings is some dictionary like\n",
    "    # {0: \"empty\", 1: \"HUB\", 2: \"EXTRACTOR\", ...}\n",
    "    # account for resources\n",
    "    # -1 --> triangle\n",
    "    # -2 --> square\n",
    "\n",
    "    # need some way of passing goal information into program at each state\n",
    "    # could pre program in goals if they are always the same\n",
    "    # goals = [((\"triangles\", 10)), ... ((\"half-circle-half-sqaure\", 10))]\n",
    "    # unless find this information in the soruce code, probably more realistic\n",
    "\n",
    "    # TODO:\n",
    "    # 1. encode products (likely some like hex/hash number describing all possible products)\n",
    "    #       - 1crcrcrcr -- red circle, idk just example\n",
    "    # 2. write code to check if something was produced since last action -- kind of links with idea below\n",
    "    # 3. find a way to account for which state gets reward added, given products take\n",
    "    #    some time to arrive at HUB --- may cause slight misoptimisation\n",
    "    #       - even better if we could have a list of products currently on belt\n",
    "    #       - then another check to see what hits HUB\n",
    "\n",
    "    def __init__(self, buildings, size, state, goals):\n",
    "\n",
    "        self.buildings = buildings # dictionary of buildings and a given index\n",
    "        self.size = size # side length of the \"board\", centre around the HUB\n",
    "        self.goals = goals\n",
    "\t\t# dictionary containing the goals of the game (or some small subset of\n",
    "\t\t# goals)\n",
    "\t\t# number of possible values of each cell\n",
    "        self.num_actions = len(buildings.keys())\n",
    "        self.state = state\n",
    "        # example from chess\n",
    "        #self.observation_space = spaces.Box(-16, 16, (8, 8))  # board 8x8\n",
    "        #self.action_space = spaces.Discrete(64 * 16 + 4)\n",
    "\n",
    "\n",
    "\n",
    "        self.observation_space = spaces.Box(0, self.num_actions, (size, size))\n",
    "        self.action_space = spaces.Discrete(size**2 * self.num_actions)\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    # naive approach\n",
    "    # any building on any possible grid -- (size^2 * num_actions)\n",
    "    ###\n",
    "    # my idea: lmk if you can think of better\n",
    "    # if resource --> extractor\n",
    "    # if empty --> belt\n",
    "    # if belt --> delete\n",
    "    # if building --> delete\n",
    "    \"\"\"\n",
    "    def get_possible_moves(self, state):\n",
    "        # to be implemented\n",
    "        actions = set()\n",
    "\n",
    "        for i in state:\n",
    "            for j in state[0]:\n",
    "                cell_val = state[i][j]\n",
    "                if cell_val == 'empty':\n",
    "                    actions.add((i, j, 'belt'))\n",
    "                if cell_val == 'resource':\n",
    "                    actions.add((i,j,'extractor'))\n",
    "\n",
    "        return actions\n",
    "\n",
    "\n",
    "    def check_produced(self):\n",
    "        # check if anything has reached the HUB\n",
    "        # alternatviely, check what is currently on belts\n",
    "        pass\n",
    "\n",
    "    def update_goal(self, product):\n",
    "\n",
    "        # minus from product goal\n",
    "        self.goals.update({product: self.goals.get(product) - 1})\n",
    "\n",
    "        # if zero more required, remove\n",
    "        if self.goals.get(product) == 0:\n",
    "            self.goals.pop(product)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # update the goals because all previous goals have been met\n",
    "    # maybe even smarter to do this in 2 or 3 level batches???\n",
    "    def update_goals(self, new_goals):\n",
    "\n",
    "        for goal in new_goals: # list of goals to be added\n",
    "            self.goals.update(goal)\n",
    "\n",
    "\n",
    "    def step(self, state, action):\n",
    "        # action should already be legal\n",
    "\n",
    "        i, j, m = action\n",
    "        state[i][j] = m\n",
    "        reward = 0\n",
    "\n",
    "        produced = self.check_produced()\n",
    "        if produced in self.goals.keys():\n",
    "            ## this wont reward properly as it will reward some state some\n",
    "\t\t\t# number of actions\n",
    "            ## after the last building placed was involved\n",
    "            ## in bad cases this will negatively reward model\n",
    "            ## eg. 1. product travelling to HUB\n",
    "            #      2. belt behind product is deleted\n",
    "            #      3. no more product can come through\n",
    "            #      4. but first state after product gets to HUB gets reward\n",
    "\n",
    "            # could reduce probability of deleting belt,\n",
    "            # or increase probability of doing action in a free space?\n",
    "\n",
    "            ######\n",
    "            # not sure how to officially solve this without manually checking a\n",
    "            # path still exists. seems slow\n",
    "            #\n",
    "            # the case described above will be rareish, at least for small factory\n",
    "            # relative to size\n",
    "            ####\n",
    "\n",
    "            # if thing has reach the HUB --> update_goal\n",
    "            self.update_goal(produced)\n",
    "\n",
    "            reward += 1 # just add one if something produced is in goals\n",
    "\n",
    "        return state, reward\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
